{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Install all dependencies\n",
    "#\n",
    "\n",
    "!pip install pandas\n",
    "!pip install boto3\n",
    "!pip install sagemaker\n",
    "!pip install matplotlib\n",
    "!pip install mxnet\n",
    "!pip install gluonts\n",
    "!pip install --upgrade \"mxnet==1.4.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run basic checks\n",
    "#\n",
    "\n",
    "import mxnet\n",
    "\n",
    "print(mxnet.__version__)\n",
    "gpu_count = mxnet.context.num_gpus()\n",
    "print(f\"The GPU count is [{gpu_count}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import dataset(s)\n",
    "# Dataset retrieved from:\n",
    "#   https://finance.yahoo.com/quote/%5EGSPC/history?period1=788936400&period2=1564545600&interval=1mo&filter=history&frequency=1mo\n",
    "#\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "BUCKET_NAME = \"sagemaker-studio-941048668662-pqxpata7h5\"\n",
    "DATASET = \"SandP_1995_2019_monthly.csv\"\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    # Download as local file\n",
    "    s3.Bucket(BUCKET_NAME).download_file(DATASET, DATASET)\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Parse dataset\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DATASET, header=0, index_col=0)\n",
    "print(\"First sample:\")\n",
    "print(df.head(1))\n",
    "print(\"\\nLast sample:\")\n",
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot available data\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Adj Close'].plot(linewidth=2)\n",
    "plt.grid(which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Configure training  and test data\n",
    "#\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "# from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# Configure training data\n",
    "# training_data = ListDataset(\n",
    "#     [{\"start\": df.index[0], \"target\": df['Adj Close'][:\"2013-12-01\"]}],\n",
    "#     freq=\"1M\"\n",
    "# )\n",
    "\n",
    "# # Configure test data\n",
    "# test_data = ListDataset(\n",
    "#     [{\"start\": df.index[0], \"target\": df['Adj Close'][:\"2015-04-15 00:00:00\"]}],\n",
    "#     freq=\"1M\"\n",
    "# )\n",
    "\n",
    "train = df[: \"2015-04-05 00:00:00\"]\n",
    "train.to_csv(\"train.csv\")\n",
    "\n",
    "test = df[: \"2015-04-15 00:00:00\"]\n",
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Upload training and test data to S3\n",
    "#\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# Configure S3\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "s3_train_data_path = \"s3://{}/gia/train\".format(s3_bucket)\n",
    "s3_test_data_path = \"s3://{}/gia/test\".format(s3_bucket)\n",
    "\n",
    "print(\"Data will be uploaded to: \", s3_bucket)\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)\n",
    "        \n",
    "copy_to_s3(\"train.csv\", s3_train_data_path + \"/train.csv\")\n",
    "copy_to_s3(\"test.csv\", s3_test_data_path + \"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
