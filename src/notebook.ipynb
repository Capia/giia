{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Install all dependencies`\n",
    "#\n",
    "\n",
    "EPOCHS = 20\n",
    "MODEL_NAME = \"gia\"\n",
    "\n",
    "!pip install pandas\n",
    "!pip install boto3\n",
    "!pip install sagemaker\n",
    "!pip install matplotlib\n",
    "!pip install mxnet==1.5.1\n",
    "!pip install gluonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Setting up logging\n",
    "#\n",
    "\n",
    "#This is a logging tool that runs as a background threaded process. This is because when we close our Jupyter notebook but leave\n",
    "#it running to train models, anything printed is not saved.\n",
    "#So instead of printing any debug info, we log() it instead, and it will go to a log file.\n",
    "#This is useful when running training over a weekend for example.\n",
    "# import logging\n",
    "# import threading\n",
    "# import datetime\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "# def setup_file_logger():\n",
    "#     log_file = \"{}-{}.log\".format(MODEL_NAME, str(datetime.datetime.now()))\n",
    "#     hdlr = logging.FileHandler(log_file)\n",
    "#     formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "#     hdlr.setFormatter(formatter)\n",
    "#     logger.addHandler(hdlr) \n",
    "#     logger.setLevel(logging.INFO)\n",
    "\n",
    "# def log(message, type='info'):\n",
    "#     #outputs to Jupyter console\n",
    "#     print('{} {}'.format(datetime.datetime.now(), message))\n",
    "#     #outputs to file\n",
    "#     if type == 'info':\n",
    "#         logger.info(message)\n",
    "#     elif type == 'warning':\n",
    "#         logger.warning(message)\n",
    "#     elif type == 'error':\n",
    "#         logger.error(message)\n",
    "#     elif type == 'critical':\n",
    "#         logger.critical(message)\n",
    "\n",
    "# threaded_logging = threading.Thread(target=setup_file_logger)\n",
    "# threaded_logging.start()\n",
    "# threaded_logging.join()\n",
    "# log(\"Background logger started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run basic checks\n",
    "#\n",
    "\n",
    "import mxnet\n",
    "\n",
    "print(mxnet.__version__)\n",
    "gpu_count = mxnet.context.num_gpus()\n",
    "print(f\"The GPU count is [{gpu_count}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import dataset(s)\n",
    "# Dataset retrieved from:\n",
    "#   https://finance.yahoo.com/quote/%5EGSPC/history?period1=788936400&period2=1564545600&interval=1mo&filter=history&frequency=1mo\n",
    "#\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "BUCKET_NAME = \"sagemaker-studio-941048668662-pqxpata7h5\"\n",
    "DATASET = \"SandP_1995_2019_monthly.csv\"\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    # Download as local file\n",
    "    s3.Bucket(BUCKET_NAME).download_file(DATASET, DATASET)\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        log(\"The object does not exist.\", \"critical\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Parse dataset\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DATASET, header=0, index_col=0)\n",
    "print(\"First sample:\")\n",
    "print(df.head(1))\n",
    "print(\"\\nLast sample:\")\n",
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot available data\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Adj Close'].plot(linewidth=2)\n",
    "plt.grid(which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Configure trainging data\n",
    "#\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "training_data = ListDataset(\n",
    "    [{\"start\": df.index[0], \"target\": df['Adj Close'][:\"2013-12-01\"]}],\n",
    "    freq=\"1M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train model on training data\n",
    "#\n",
    "\n",
    "#from gluonts.dataset.artificial._base import ComplexSeasonalTimeSeries\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "# estimator = SimpleFeedForwardEstimator(\n",
    "#     num_hidden_dimensions=[1],\n",
    "#     prediction_length=12,\n",
    "#     context_length=100,\n",
    "#     freq=\"1M\",\n",
    "#     trainer=Trainer(\n",
    "#         epochs=10, \n",
    "#         learning_rate=1e-3, \n",
    "#         num_batches_per_epoch=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "estimator = DeepAREstimator(freq=\"1M\", prediction_length=12, trainer=Trainer(epochs=EPOCHS))\n",
    "predictor = estimator.train(training_data=training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "# Configure test data\n",
    "test_data = ListDataset(\n",
    "    [{\"start\": df.index[0], \"target\": df['Adj Close'][:\"2015-04-15 00:00:00\"]}],\n",
    "    freq=\"1M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=test_data,  # test dataset\n",
    "    predictor=predictor,  # predictor\n",
    "    num_samples=100,  # number of sample paths we want for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "\n",
    "forecast_entry = forecasts[0]\n",
    "ts_entry = tss[0]\n",
    "\n",
    "print(f\"Number of sample paths: {forecast_entry.num_samples}\")\n",
    "print(f\"Dimension of samples: {forecast_entry.samples.shape}\")\n",
    "print(f\"Start date of the forecast window: {forecast_entry.start_date}\")\n",
    "print(f\"Frequency of the time series: {forecast_entry.freq}\")\n",
    "\n",
    "print(f\"Mean of the future window:\\n {forecast_entry.mean}\")\n",
    "print(f\"0.5-quantile (median) of the future window:\\n {forecast_entry.quantile(0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prob_forecasts(ts_entry, forecast_entry):\n",
    "    plot_length = 150\n",
    "    prediction_intervals = (50.0, 90.0)\n",
    "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series\n",
    "    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')\n",
    "    plt.grid(which=\"both\")\n",
    "    plt.legend(legend, loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "plot_prob_forecasts(ts_entry, forecast_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Model\n",
    "import json\n",
    "from gluonts.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_data))\n",
    "\n",
    "print(json.dumps(agg_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Save the model\n",
    "#\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "forecast_output = \"gia_forecast\"\n",
    "os.makedirs(forecast_output, exist_ok=True)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "forecast_output_instance = forecast_output + \"/run_\" + now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "os.makedirs(forecast_output_instance, exist_ok=True)\n",
    "\n",
    "predictor.serialize_prediction_net(pathlib.Path(forecast_output_instance))\n",
    "predictor.serialize(pathlib.Path(forecast_output_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
