{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Setup constants\n",
    "#\n",
    "\n",
    "import subprocess\n",
    "\n",
    "MODEL_NAME = \"giia\"\n",
    "MODEL_VERSION = \"0.3.3\"\n",
    "DATASETS = [\n",
    "    \"datasets/SandP_1995_2020_daily.csv\",\n",
    "    \"datasets/AWK_2008IPO_2020_daily.csv\"\n",
    "]\n",
    "SM_ROLE ='arn:aws:iam::941048668662:role/service-role/AmazonSageMaker-ExecutionRole-20191206T145896'\n",
    "\n",
    "MODULE_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%cache magic is now registered in ipython\n",
      "loading cached value for variable 'MODULE_PATH'. Time since pickling  9 days, 0:25:04.606537\n",
      "2020-07-03 15:16:52.929588 Background logger started\n",
      "2020-07-03 15:16:52.930171 Current working directory [/Users/jbeckman/giia/src]\n",
      "2020-07-03 15:16:52.930341 1.6.0\n",
      "2020-07-03 15:16:52.930599 The GPU count is [0]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Initialization\n",
    "#\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cache_magic\n",
    "from pathlib import Path\n",
    "\n",
    "# Set notebook's src module path. Note that you may have to update your IDE's project settings to do the same for the\n",
    "#  local library imports to work the same\n",
    "%cache MODULE_PATH = os.path.dirname(Path().resolve())\n",
    "sys.path.append(MODULE_PATH)\n",
    "\n",
    "# Keep paths consistent throughout notebook\n",
    "os.chdir(MODULE_PATH)\n",
    "\n",
    "# Autoreload imports at the beginning of cell execution.\n",
    "#  https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.logging import LoggerUtil\n",
    "from utils.utils import Utils\n",
    "\n",
    "LOGGER = LoggerUtil(f\"{MODEL_NAME}-{MODEL_VERSION}\")\n",
    "UTILS = Utils(LOGGER)\n",
    "\n",
    "LOGGER.log(\"Current working directory [{}]\".format(os.getcwd()))\n",
    "UTILS.describe_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Open       High        Low  Close  Adj Close    Volume\n",
      "Date                                                              \n",
      "2008-04-23  20.6  21.450001  20.219999   20.6  14.833152  23402800\n",
      "            Open       High        Low  Close  Adj Close      Volume\n",
      "Date                                                                \n",
      "2008-04-23  10.3  10.725001  10.109999   10.3   7.416576  11701400.0\n",
      "[10.3       10.3599995 10.5       ... 63.8549995 62.169998  62.200001 ]\n",
      "-----------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-61221e0b51e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4303\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.read_csv(\"datasets/AWK_2008IPO_2020_daily.csv\", header=0, index_col=0)\n",
    "print(df_1.head(1))\n",
    "\n",
    "df_2 = pd.read_csv(\"datasets/AWK_2008IPO_2020_daily.csv\", header=0, index_col=0)\n",
    "df_2 /= 2\n",
    "print(df_2.head(1))\n",
    "print(df_2[\"Open\"].to_numpy())\n",
    "\n",
    "print(\"-----------------------\")\n",
    "# for (columnName, columnData) in df_2.iteritems():\n",
    "#     print(columnName)\n",
    "#     print(columnData.to_numpy())\n",
    "    \n",
    "dataframes = []\n",
    "dataframes.append(df_1.set_index([\"Date\"]))\n",
    "dataframes.append(df_2.set_index([\"Date\"]))\n",
    "\n",
    "combined_df = pd.concat(dataframes)\n",
    "print(combined_df)\n",
    "\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis = 1)\n",
    "# print(df.head(1))\n",
    "\n",
    "# import xarray\n",
    "#\n",
    "# output_as_dataarray = xarray.concat(\n",
    "#     [xarray.DataArray(X,\n",
    "#                       dims=['record', 'edge'],\n",
    "#                       coords={'record': range(X.shape[0]),\n",
    "#                               'edge': ['start', 'end']},\n",
    "#                      ) for X in (A, B, C)],\n",
    "#     dim='descriptor',\n",
    "# ).assign_coords(descriptor=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_missing_values(dataset: list):\n",
    "    max_len = max(len(sublist) for sublist in dataset)\n",
    "    for sublist in dataset:\n",
    "        sublist.extend([np.nan] * (max_len - len(sublist)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
