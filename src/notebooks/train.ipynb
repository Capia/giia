{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory [/Users/jbeckman/projects/capia/giia/src]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Initialization\n",
    "#\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import ipynbname\n",
    "from pathlib import Path\n",
    "\n",
    "# Set notebook's src module path. Note that you may have to update your IDE's project settings to do the same for the\n",
    "#  local library imports to work the same\n",
    "MODULE_PATH = ipynbname.path().parent.parent\n",
    "sys.path.append(str(MODULE_PATH))\n",
    "\n",
    "# Keep paths consistent throughout notebook\n",
    "os.chdir(MODULE_PATH)\n",
    "\n",
    "# This should always be `./src`\n",
    "print(f\"Current working directory [{os.getcwd()}]\")\n",
    "\n",
    "# Place all local artifacts in a disposable, git-ignored directory\n",
    "local_artifact_dir = Path(os.getcwd()).parent / \"out\"\n",
    "local_artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Autoreload imports at the beginning of cell execution.\n",
    "#  https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-08 17:27:10.282038 Background logger started\n",
      "2023-02-08 17:27:10.282824 The model id is [giia-1.0.3]\n",
      "2023-02-08 17:27:10.282922 The MXNet version is [1.9.1]\n",
      "2023-02-08 17:27:10.282988 The GluonTS version is [0.12.0]\n",
      "2023-02-08 17:27:10.283059 The SageMaker version is [2.111.0]\n",
      "2023-02-08 17:27:10.283160 The GPU count is [0]\n",
      "2023-02-08 17:27:10.293145 The nvidia-smi binary was not found and thus GPU computation is not supported. Using the default CPU computation\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Setup utils\n",
    "#\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from utils.logger_util import LoggerUtil\n",
    "from utils.utils import Utils\n",
    "from utils import config\n",
    "\n",
    "LOGGER = LoggerUtil(config.MODEL_ID, local_artifact_dir / \"logs\")\n",
    "UTILS = Utils(LOGGER)\n",
    "\n",
    "UTILS.describe_env()\n",
    "\n",
    "# AWS instance specs can be found here https://aws.amazon.com/sagemaker/pricing/\n",
    "AWS_INSTANCE = 'ml.m5.large' # 2 vCPU, 0 GPU, 8 GB memory, $0.134/hour\n",
    "AWS_INSTANCE_2 = 'ml.m5.4xlarge' # 16 vCPU, 0 GPU, 64 GB memory, $0.922/hour\n",
    "AWS_GPU_INSTANCE = 'ml.g4dn.xlarge' # 4 vCPU, 1 GPU, 16 GB memory, $0.736/hour\n",
    "AWS_GPU_INSTANCE_2 = 'ml.g4dn.2xlarge' # 8 vCPU, 1 GPU, 32 GB memory, $1.053/hour\n",
    "AWS_GPU_INSTANCE_3 = 'ml.g4dn.4xlarge' # 16 vCPU, 1 GPU, 64 GB memory, $1.505/hour\n",
    "AWS_GPU_INSTANCE_4 = 'ml.g4dn.8xlarge' # 32 vCPU, 1 GPU, 128 GB memory, $2.72/hour\n",
    "AWS_GPU_INSTANCE_5 = 'ml.g4dn.16xlarge' # 64 vCPU, 1 GPU, 256 GB memory, $5.44/hour\n",
    "LOCAL_INSTANCE = 'local'\n",
    "try:\n",
    "    if subprocess.call('nvidia-smi') == 0:\n",
    "        LOCAL_INSTANCE = 'local_gpu'\n",
    "except:\n",
    "    LOGGER.log(\"The nvidia-smi binary was not found and thus GPU computation is not supported. Using the default CPU \"\n",
    "               \"computation\")\n",
    "\n",
    "# Change this to your desired instance type\n",
    "INSTANCE_TYPE = LOCAL_INSTANCE\n",
    "IS_LOCAL = LOCAL_INSTANCE == INSTANCE_TYPE\n",
    "\n",
    "# Does the model use filedataset or CSVs\n",
    "FILEDATASET_BASED = True\n",
    "\n",
    "# Is the model univariate\n",
    "ONE_DIM_TARGET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:17:03.430711 First sample:\n",
      "2023-02-08 20:17:03.433964 \n",
      "              open    high     low   close  volume\n",
      "date                                              \n",
      "2020-01-01  128.66  128.66  128.66  128.66     0.0\n",
      "2023-02-08 20:17:03.434283 Last sample:\n",
      "2023-02-08 20:17:03.437602 \n",
      "                        open    high      low   close     volume\n",
      "date                                                            \n",
      "2023-02-07 01:43:00  1624.49  1624.6  1624.49  1624.6  23.077475\n",
      "2023-02-08 20:17:03.437764 Number of rows: 1631624\n",
      "2023-02-08 20:17:03.437858 Number of raw columns: 5\n",
      "2023-02-08 20:17:03.469034 Train dataset starts at: 2020-01-01 00:00:00\n",
      "2023-02-08 20:17:03.469244 Test dataset starts at: 2022-03-04 03:36:00\n",
      "2023-02-08 20:17:03.469329 Building a univariate FileDataset\n",
      "2023-02-08 20:17:03.483304 Parsed train and test datasets can be found in [/Users/jbeckman/projects/capia/giia/out/datasets]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Parse dataset\n",
    "#\n",
    "\n",
    "from data_processing.parse import Parse\n",
    "\n",
    "PARSE = Parse(LOGGER)\n",
    "\n",
    "dataset_dir_path = local_artifact_dir / \"datasets\"\n",
    "\n",
    "# Creates train and test dataset\n",
    "PARSE.create_train_test_dataset(\n",
    "    dataset_dir_path,\n",
    "    filedataset_based=FILEDATASET_BASED,\n",
    "    one_dim_target=ONE_DIM_TARGET,\n",
    "    starting_date_truncate=\"2020-01-01 00:00:00\"\n",
    "    # starting_date_truncate=\"2021-03-01 00:00:00\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-08 20:17:47.696334 Notebook is set to local mode, not uploading to S3\n",
      "2023-02-08 20:17:47.729519 Model output dir is [file:///Users/jbeckman/projects/capia/giia/out/giia-1.0.3/models]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Setup local/aws environment. If aws, upload the datasets to S3\n",
    "#\n",
    "\n",
    "from data_processing.aws_handler import AWSHandler\n",
    "from sagemaker import LocalSession\n",
    "\n",
    "AWS_HANDLER = AWSHandler(LOGGER, config.MODEL_ID)\n",
    "\n",
    "sagemaker_session = None\n",
    "\n",
    "model_output_dir_path = local_artifact_dir / config.MODEL_ID / \"models\"\n",
    "model_output_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if IS_LOCAL:\n",
    "    LOGGER.log(\"Notebook is set to local mode, not uploading to S3\")\n",
    "\n",
    "    dataset_dir_uri = f\"file://{dataset_dir_path}\"\n",
    "    model_output_dir_uri = f\"file://{model_output_dir_path}\"\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {\n",
    "        'local': {\n",
    "            'local_code': True,\n",
    "            'container_root': str(model_output_dir_path)\n",
    "        }\n",
    "    }\n",
    "else:\n",
    "    sagemaker_session = AWS_HANDLER.sagemaker_session\n",
    "\n",
    "    AWS_HANDLER.upload_train_datasets(dataset_dir_path, filedataset_based=FILEDATASET_BASED)\n",
    "    dataset_dir_uri = AWS_HANDLER.s3_dataset_dir_uri\n",
    "\n",
    "    model_output_dir_uri = AWS_HANDLER.s3_model_output_uri\n",
    "\n",
    "LOGGER.log(f\"Model output dir is [{model_output_dir_uri}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ljdtjtdlf1-algo-1-xjt6p ... \r\n",
      "Creating ljdtjtdlf1-algo-1-xjt6p ... done\r\n",
      "Attaching to ljdtjtdlf1-algo-1-xjt6p\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,790 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,802 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,818 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,897 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,913 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1-xjt6p\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch_size\":256,\"context_length\":5,\"distr_output\":\"StudentTOutput\",\"epochs\":100,\"learning_rate\":0.001,\"n_hidden_layer\":10,\"n_neurons_per_layer\":560,\"num_batches_per_epoch\":100,\"prediction_length\":5}', 'SM_USER_ENTRY_POINT': 'sff.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1-xjt6p\",\"hosts\":[\"algo-1-xjt6p\"]}', 'SM_INPUT_DATA_CONFIG': '{\"dataset\":{\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"dataset\"]', 'SM_CURRENT_HOST': 'algo-1-xjt6p', 'SM_CURRENT_INSTANCE_TYPE': 'local', 'SM_CURRENT_INSTANCE_GROUP': 'homogeneousCluster', 'SM_CURRENT_INSTANCE_GROUP_HOSTS': '[]', 'SM_INSTANCE_GROUPS': '[]', 'SM_INSTANCE_GROUPS_DICT': '{}', 'SM_DISTRIBUTION_INSTANCE_GROUPS': '[]', 'SM_IS_HETERO': 'false', 'SM_MODULE_NAME': 'sff', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '6', 'SM_NUM_GPUS': '0', 'SM_NUM_NEURONS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': '/opt/ml/code', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1-xjt6p\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-xjt6p\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-xjt6p\"],\"hyperparameters\":{\"batch_size\":256,\"context_length\":5,\"distr_output\":\"StudentTOutput\",\"epochs\":100,\"learning_rate\":0.001,\"n_hidden_layer\":10,\"n_neurons_per_layer\":560,\"num_batches_per_epoch\":100,\"prediction_length\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"mxnet-training-2023-02-09-01-45-08-163\",\"log_level\":20,\"master_hostname\":\"algo-1-xjt6p\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"sff\",\"network_interface_name\":\"eth0\",\"num_cpus\":6,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-xjt6p\",\"hosts\":[\"algo-1-xjt6p\"]},\"user_entry_point\":\"sff.py\"}', 'SM_USER_ARGS': '[\"--batch_size\",\"256\",\"--context_length\",\"5\",\"--distr_output\",\"StudentTOutput\",\"--epochs\",\"100\",\"--learning_rate\",\"0.001\",\"--n_hidden_layer\",\"10\",\"--n_neurons_per_layer\",\"560\",\"--num_batches_per_epoch\",\"100\",\"--prediction_length\",\"5\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_DATASET': '/opt/ml/input/data/dataset', 'SM_HP_EPOCHS': '100', 'SM_HP_BATCH_SIZE': '256', 'SM_HP_CONTEXT_LENGTH': '5', 'SM_HP_PREDICTION_LENGTH': '5', 'SM_HP_LEARNING_RATE': '0.001', 'SM_HP_N_HIDDEN_LAYER': '10', 'SM_HP_N_NEURONS_PER_LAYER': '560', 'SM_HP_DISTR_OUTPUT': 'StudentTOutput', 'SM_HP_NUM_BATCHES_PER_EPOCH': '100'}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:45:14,931 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m /usr/bin/python3 -m pip install -r requirements.txt\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting PyYAML==6.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m701.2/701.2 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jupyterlab==3.6.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyterlab-3.6.1-py3-none-any.whl (8.9 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.9/8.9 MB\u001B[0m \u001B[31m19.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting matplotlib==3.6.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.4/9.4 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting boto3==1.24.59\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading boto3-1.24.59-py3-none-any.whl (132 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m132.5/132.5 kB\u001B[0m \u001B[31m26.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting ipynbname==2021.3.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ipynbname-2021.3.2-py3-none-any.whl (4.0 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting numpy==1.23.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.1/17.1 MB\u001B[0m \u001B[31m31.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting pandas==1.5.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.2/12.2 MB\u001B[0m \u001B[31m34.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting s3fs==2023.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading s3fs-2023.1.0-py3-none-any.whl (27 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting setuptools==67.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading setuptools-67.1.0-py3-none-any.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m32.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0meta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: wheel==0.38.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (0.38.4)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting sagemaker==2.111.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading sagemaker-2.111.0.tar.gz (577 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m577.4/577.4 kB\u001B[0m \u001B[31m36.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jenkspy==0.3.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jenkspy-0.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (527 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m527.1/527.1 kB\u001B[0m \u001B[31m35.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting tqdm==4.64.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.5/78.5 kB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting nbstripout==0.6.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nbstripout-0.6.1-py2.py3-none-any.whl (15 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting gluonts==0.12.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading gluonts-0.12.1-py3-none-any.whl (1.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m27.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0meta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.6.1->-r requirements.txt (line 2)) (3.1.2)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-core\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.3/94.3 kB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jupyter-server<3,>=1.16.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_server-2.2.1-py3-none-any.whl (365 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m365.3/365.3 kB\u001B[0m \u001B[31m39.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting nbclassic\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nbclassic-0.5.1-py3-none-any.whl (10.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.0/10.0 MB\u001B[0m \u001B[31m27.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.6.1->-r requirements.txt (line 2)) (21.3)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from jupyterlab==3.6.1->-r requirements.txt (line 2)) (6.2)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-ydoc~=0.2.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_ydoc-0.2.2-py3-none-any.whl (5.6 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting ipython\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ipython-8.9.0-py3-none-any.whl (783 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m783.1/783.1 kB\u001B[0m \u001B[31m43.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jupyter-server-ydoc<0.7.0,>=0.6.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_server_ydoc-0.6.1-py3-none-any.whl (11 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting tomli\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting notebook<7\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m439.1/439.1 kB\u001B[0m \u001B[31m33.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jupyterlab-server~=2.19\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyterlab_server-2.19.0-py3-none-any.whl (56 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.4/56.4 kB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (9.3.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (1.0.6)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (1.4.4)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (0.11.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (4.38.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (2.8.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.6.3->-r requirements.txt (line 3)) (3.0.9)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting botocore<1.28.0,>=1.27.59\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading botocore-1.27.96-py3-none-any.whl (9.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.3/9.3 MB\u001B[0m \u001B[31m18.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from boto3==1.24.59->-r requirements.txt (line 4)) (0.6.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3==1.24.59->-r requirements.txt (line 4)) (1.0.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting ipykernel\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ipykernel-6.21.1-py3-none-any.whl (149 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m149.8/149.8 kB\u001B[0m \u001B[31m9.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2022.6)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting python-dateutil>=2.7\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m247.7/247.7 kB\u001B[0m \u001B[31m20.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting fsspec==2023.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.0/143.0 kB\u001B[0m \u001B[31m15.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aiohttp-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m21.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0meta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting aiobotocore~=2.4.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aiobotocore-2.4.2-py3-none-any.whl (66 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.8/66.8 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: attrs<23,>=20.3.0 in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (22.1.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: google-pasta in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (0.2.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (4.13.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: pathos in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (0.3.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (0.1.5)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: protobuf<4.0,>=3.1 in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (3.19.6)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: schema in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (0.7.5)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /usr/local/lib/python3.8/dist-packages (from sagemaker==2.111.0->-r requirements.txt (line 11)) (1.0.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting nbformat\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.1/78.1 kB\u001B[0m \u001B[31m14.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting toolz~=0.10\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.8/55.8 kB\u001B[0m \u001B[31m12.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.8/dist-packages (from gluonts==0.12.1->-r requirements.txt (line 16)) (4.4.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting pydantic~=1.7\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pydantic-1.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting wrapt>=1.10.10\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.0/81.0 kB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting aioitertools>=0.5.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting botocore<1.28.0,>=1.27.59\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading botocore-1.27.59-py3-none-any.whl (9.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.1/9.1 MB\u001B[0m \u001B[31m14.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting multidict<7.0,>=4.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.3/121.3 kB\u001B[0m \u001B[31m20.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting frozenlist>=1.1.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m161.3/161.3 kB\u001B[0m \u001B[31m24.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2023.1.0->-r requirements.txt (line 8)) (2.1.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting yarl<2.0,>=1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m262.1/262.1 kB\u001B[0m \u001B[31m25.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting aiosignal>=1.1.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting async-timeout<5.0,>=4.0.0a3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/dist-packages (from botocore<1.28.0,>=1.27.59->boto3==1.24.59->-r requirements.txt (line 4)) (1.26.12)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.111.0->-r requirements.txt (line 11)) (3.10.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.1->jupyterlab==3.6.1->-r requirements.txt (line 2)) (2.1.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting argon2-cffi\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-server-terminals\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-events>=0.4.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-client>=7.4.4\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_client-8.0.2-py3-none-any.whl (103 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m103.3/103.3 kB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting traitlets>=5.6.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m117.4/117.4 kB\u001B[0m \u001B[31m22.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting send2trash\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting anyio>=3.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m80.6/80.6 kB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting prometheus-client\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m122.5/122.5 kB\u001B[0m \u001B[31m24.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting pyzmq>=24\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pyzmq-25.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m29.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0meta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting terminado>=0.8.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting websocket-client\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.9/55.9 kB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting nbconvert>=6.4.4\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nbconvert-7.2.9-py3-none-any.whl (274 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m274.9/274.9 kB\u001B[0m \u001B[31m22.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting platformdirs>=2.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading platformdirs-3.0.0-py3-none-any.whl (14 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-server-fileid<1,>=0.6.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_server_fileid-0.6.0-py3-none-any.whl (15 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting ypy-websocket<0.9.0,>=0.8.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ypy_websocket-0.8.2-py3-none-any.whl (10 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting y-py<0.6.0,>=0.5.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading y_py-0.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m24.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jsonschema>=4.17.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m90.4/90.4 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting json5>=0.9.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading json5-0.9.11-py2.py3-none-any.whl (19 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting babel>=2.10\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.5/9.5 MB\u001B[0m \u001B[31m23.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.8/dist-packages (from jupyterlab-server~=2.19->jupyterlab==3.6.1->-r requirements.txt (line 2)) (2.28.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting fastjsonschema\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting nest-asyncio>=1.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting ipython-genutils\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting notebook-shim>=0.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker==2.111.0->-r requirements.txt (line 11)) (1.16.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting comm>=0.1.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from ipykernel->ipynbname==2021.3.2->-r requirements.txt (line 5)) (5.9.4)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting matplotlib-inline>=0.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting debugpy>=1.6.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m26.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting stack-data\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting pexpect>4.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m59.0/59.0 kB\u001B[0m \u001B[31m15.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting jedi>=0.16\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m19.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting prompt-toolkit<3.1.0,>=3.0.30\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m386.4/386.4 kB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting backcall\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting decorator\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting pygments>=2.4.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m20.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting pickleshare\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: multiprocess>=0.70.14 in /usr/local/lib/python3.8/dist-packages (from pathos->sagemaker==2.111.0->-r requirements.txt (line 11)) (0.70.14)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: pox>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from pathos->sagemaker==2.111.0->-r requirements.txt (line 11)) (0.3.2)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from pathos->sagemaker==2.111.0->-r requirements.txt (line 11)) (0.3.6)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: ppft>=1.7.6.6 in /usr/local/lib/python3.8/dist-packages (from pathos->sagemaker==2.111.0->-r requirements.txt (line 11)) (1.7.6.6)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema->sagemaker==2.111.0->-r requirements.txt (line 11)) (21.6.0)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab==3.6.1->-r requirements.txt (line 2)) (3.4)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting sniffio>=1.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting parso<0.9.0,>=0.8.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m100.8/100.8 kB\u001B[0m \u001B[31m17.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.5/57.5 kB\u001B[0m \u001B[31m13.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting importlib-resources>=1.4.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading importlib_resources-5.10.2-py3-none-any.whl (34 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting pkgutil-resolve-name>=1.3.10\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting rfc3339-validator\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting rfc3986-validator>=0.1.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting python-json-logger>=2.0.4\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyter-events>=0.4.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyter_events-0.5.0-py3-none-any.whl (17 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting pandocfilters>=1.4.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting tinycss2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jupyterlab-pygments\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting nbclient>=0.5.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m72.0/72.0 kB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting defusedxml\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting bleach\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m162.5/162.5 kB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting mistune<3,>=2.0.3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading mistune-2.0.5-py2.py3-none-any.whl (24 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting beautifulsoup4\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m129.4/129.4 kB\u001B[0m \u001B[31m24.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting ptyprocess>=0.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting wcwidth\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.28->jupyterlab-server~=2.19->jupyterlab==3.6.1->-r requirements.txt (line 2)) (2022.9.24)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting aiosqlite<1,>=0.17.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aiosqlite-0.18.0-py3-none-any.whl (15 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting aiofiles<23,>=22.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting argon2-cffi-bindings\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.2/86.2 kB\u001B[0m \u001B[31m17.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hCollecting pure-eval\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting executing>=1.2.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting asttokens>=2.1.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting jsonpointer>1.13\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting uri-template\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting isoduration\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting webcolors>=1.11\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting fqdn\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab==3.6.1->-r requirements.txt (line 2)) (1.15.1)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting soupsieve>1.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting webencodings\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=1.16.0->jupyterlab==3.6.1->-r requirements.txt (line 2)) (2.21)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Collecting arrow>=0.15.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m66.4/66.4 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m1m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25hBuilding wheels for collected packages: sagemaker\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Building wheel for sagemaker (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[?25h  Created wheel for sagemaker: filename=sagemaker-2.111.0-py2.py3-none-any.whl size=793032 sha256=d46e611a76b8472dc33ad6ae9450426d17d73ca1c637f78586ce6a257bfb675b\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Stored in directory: /root/.cache/pip/wheels/b8/d6/40/2111d3cc80ed35c27ae7dcaa62f959ce5e64b367ea93812c19\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Successfully built sagemaker\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Installing collected packages: y-py, webencodings, wcwidth, send2trash, pure-eval, ptyprocess, pickleshare, mistune, json5, ipython-genutils, fastjsonschema, executing, backcall, wrapt, websocket-client, webcolors, uri-template, traitlets, tqdm, toolz, tomli, tinycss2, terminado, soupsieve, sniffio, setuptools, rfc3986-validator, rfc3339-validator, pyzmq, PyYAML, python-json-logger, python-dateutil, pyrsistent, pygments, pydantic, prompt-toolkit, prometheus-client, platformdirs, pkgutil-resolve-name, pexpect, parso, pandocfilters, numpy, nest-asyncio, multidict, jupyterlab-pygments, jsonpointer, importlib-resources, fsspec, frozenlist, fqdn, defusedxml, decorator, debugpy, bleach, babel, async-timeout, asttokens, aiosqlite, aioitertools, aiofiles, ypy-websocket, yarl, stack-data, pandas, matplotlib-inline, jupyter-ydoc, jupyter-server-terminals, jupyter-core, jsonschema, jenkspy, jedi, comm, botocore, beautifulsoup4, arrow, argon2-cffi-bindings, anyio, aiosignal, nbformat, matplotlib, jupyter-client, isoduration, ipython, gluonts, argon2-cffi, aiohttp, nbstripout, nbclient, ipykernel, boto3, aiobotocore, sagemaker, s3fs, nbconvert, jupyter-events, ipynbname, jupyter-server, notebook-shim, jupyterlab-server, jupyter-server-fileid, nbclassic, jupyter-server-ydoc, notebook, jupyterlab\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: tqdm\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: tqdm 4.39.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling tqdm-4.39.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled tqdm-4.39.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: setuptools\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: setuptools 45.2.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling setuptools-45.2.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled setuptools-45.2.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: PyYAML\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: PyYAML 5.4.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling PyYAML-5.4.1:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled PyYAML-5.4.1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: python-dateutil\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: python-dateutil 2.8.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling python-dateutil-2.8.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled python-dateutil-2.8.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: numpy\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: numpy 1.19.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling numpy-1.19.5:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled numpy-1.19.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: fsspec\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: fsspec 2022.11.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling fsspec-2022.11.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled fsspec-2022.11.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: pandas\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: pandas 1.3.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling pandas-1.3.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled pandas-1.3.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: botocore\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: botocore 1.29.11\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling botocore-1.29.11:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled botocore-1.29.11\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: matplotlib\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: matplotlib 3.6.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling matplotlib-3.6.2:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled matplotlib-3.6.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: boto3\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: boto3 1.26.11\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling boto3-1.26.11:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled boto3-1.26.11\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: sagemaker\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: sagemaker 2.117.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling sagemaker-2.117.0:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled sagemaker-2.117.0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   Attempting uninstall: s3fs\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Found existing installation: s3fs 0.4.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     Uninstalling s3fs-0.4.2:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m       Successfully uninstalled s3fs-0.4.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m scipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m awscli 1.27.11 requires botocore==1.29.11, but you have botocore 1.27.59 which is incompatible.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m awscli 1.27.11 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[0mSuccessfully installed PyYAML-6.0 aiobotocore-2.4.2 aiofiles-22.1.0 aiohttp-3.8.3 aioitertools-0.11.0 aiosignal-1.3.1 aiosqlite-0.18.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 async-timeout-4.0.2 babel-2.11.0 backcall-0.2.0 beautifulsoup4-4.11.2 bleach-6.0.0 boto3-1.24.59 botocore-1.27.59 comm-0.1.2 debugpy-1.6.6 decorator-5.1.1 defusedxml-0.7.1 executing-1.2.0 fastjsonschema-2.16.2 fqdn-1.5.1 frozenlist-1.3.3 fsspec-2023.1.0 gluonts-0.12.1 importlib-resources-5.10.2 ipykernel-6.21.1 ipynbname-2021.3.2 ipython-8.9.0 ipython-genutils-0.2.0 isoduration-20.11.0 jedi-0.18.2 jenkspy-0.3.2 json5-0.9.11 jsonpointer-2.3 jsonschema-4.17.3 jupyter-client-8.0.2 jupyter-core-5.2.0 jupyter-events-0.5.0 jupyter-server-2.2.1 jupyter-server-fileid-0.6.0 jupyter-server-terminals-0.4.4 jupyter-server-ydoc-0.6.1 jupyter-ydoc-0.2.2 jupyterlab-3.6.1 jupyterlab-pygments-0.2.2 jupyterlab-server-2.19.0 matplotlib-3.6.3 matplotlib-inline-0.1.6 mistune-2.0.5 multidict-6.0.4 nbclassic-0.5.1 nbclient-0.7.2 nbconvert-7.2.9 nbformat-5.7.3 nbstripout-0.6.1 nest-asyncio-1.5.6 notebook-6.5.2 notebook-shim-0.2.2 numpy-1.23.5 pandas-1.5.3 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pkgutil-resolve-name-1.3.10 platformdirs-3.0.0 prometheus-client-0.16.0 prompt-toolkit-3.0.36 ptyprocess-0.7.0 pure-eval-0.2.2 pydantic-1.10.4 pygments-2.14.0 pyrsistent-0.19.3 python-dateutil-2.8.2 python-json-logger-2.0.4 pyzmq-25.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 s3fs-2023.1.0 sagemaker-2.111.0 send2trash-1.8.0 setuptools-67.1.0 sniffio-1.3.0 soupsieve-2.3.2.post1 stack-data-0.6.2 terminado-0.17.1 tinycss2-1.2.1 tomli-2.0.1 toolz-0.12.0 tqdm-4.64.1 traitlets-5.9.0 uri-template-1.2.0 wcwidth-0.2.6 webcolors-1.12 webencodings-0.5.1 websocket-client-1.5.1 wrapt-1.14.1 y-py-0.5.5 yarl-1.8.2 ypy-websocket-0.8.2\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3 -m pip install --upgrade pip\u001B[0m\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,494 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,502 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,535 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,536 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,544 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,577 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,586 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,591 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,621 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:27,630 sagemaker-training-toolkit INFO     Invoking user script\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Training Env:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"additional_framework_parameters\": {},\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"channel_input_dirs\": {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"dataset\": \"/opt/ml/input/data/dataset\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     },\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"current_host\": \"algo-1-xjt6p\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"current_instance_group\": \"homogeneousCluster\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"current_instance_group_hosts\": [],\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"current_instance_type\": \"local\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"distribution_hosts\": [\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"algo-1-xjt6p\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     ],\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"distribution_instance_groups\": [],\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"framework_module\": \"sagemaker_mxnet_container.training:main\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"hosts\": [\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"algo-1-xjt6p\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     ],\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"hyperparameters\": {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"epochs\": 100,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"batch_size\": 256,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"context_length\": 5,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"prediction_length\": 5,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"learning_rate\": 0.001,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"n_hidden_layer\": 10,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"n_neurons_per_layer\": 560,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"distr_output\": \"StudentTOutput\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"num_batches_per_epoch\": 100\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     },\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"input_config_dir\": \"/opt/ml/input/config\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"input_data_config\": {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"dataset\": {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m             \"TrainingInputMode\": \"File\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         }\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     },\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"input_dir\": \"/opt/ml/input\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"instance_groups\": [],\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"instance_groups_dict\": {},\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"is_hetero\": false,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"is_master\": true,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"is_modelparallel_enabled\": null,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"is_smddpmprun_installed\": false,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"job_name\": \"mxnet-training-2023-02-09-01-45-08-163\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"log_level\": 20,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"master_hostname\": \"algo-1-xjt6p\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"model_dir\": \"/opt/ml/model\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"module_dir\": \"/opt/ml/code\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"module_name\": \"sff\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"network_interface_name\": \"eth0\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"num_cpus\": 6,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"num_gpus\": 0,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"num_neurons\": 0,\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"output_data_dir\": \"/opt/ml/output/data\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"output_dir\": \"/opt/ml/output\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"resource_config\": {\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"current_host\": \"algo-1-xjt6p\",\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         \"hosts\": [\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m             \"algo-1-xjt6p\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m         ]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     },\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     \"user_entry_point\": \"sff.py\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m }\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Environment variables:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HOSTS=[\"algo-1-xjt6p\"]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_NETWORK_INTERFACE_NAME=eth0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HPS={\"batch_size\":256,\"context_length\":5,\"distr_output\":\"StudentTOutput\",\"epochs\":100,\"learning_rate\":0.001,\"n_hidden_layer\":10,\"n_neurons_per_layer\":560,\"num_batches_per_epoch\":100,\"prediction_length\":5}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_USER_ENTRY_POINT=sff.py\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_FRAMEWORK_PARAMS={}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-xjt6p\",\"hosts\":[\"algo-1-xjt6p\"]}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_INPUT_DATA_CONFIG={\"dataset\":{\"TrainingInputMode\":\"File\"}}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CHANNELS=[\"dataset\"]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CURRENT_HOST=algo-1-xjt6p\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CURRENT_INSTANCE_TYPE=local\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_INSTANCE_GROUPS=[]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_INSTANCE_GROUPS_DICT={}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_IS_HETERO=false\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_MODULE_NAME=sff\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_LOG_LEVEL=20\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_INPUT_DIR=/opt/ml/input\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_OUTPUT_DIR=/opt/ml/output\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_NUM_CPUS=6\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_NUM_GPUS=0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_NUM_NEURONS=0\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_MODEL_DIR=/opt/ml/model\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_MODULE_DIR=/opt/ml/code\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1-xjt6p\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-xjt6p\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1-xjt6p\"],\"hyperparameters\":{\"batch_size\":256,\"context_length\":5,\"distr_output\":\"StudentTOutput\",\"epochs\":100,\"learning_rate\":0.001,\"n_hidden_layer\":10,\"n_neurons_per_layer\":560,\"num_batches_per_epoch\":100,\"prediction_length\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"mxnet-training-2023-02-09-01-45-08-163\",\"log_level\":20,\"master_hostname\":\"algo-1-xjt6p\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"sff\",\"network_interface_name\":\"eth0\",\"num_cpus\":6,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-xjt6p\",\"hosts\":[\"algo-1-xjt6p\"]},\"user_entry_point\":\"sff.py\"}\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_USER_ARGS=[\"--batch_size\",\"256\",\"--context_length\",\"5\",\"--distr_output\",\"StudentTOutput\",\"--epochs\",\"100\",\"--learning_rate\",\"0.001\",\"--n_hidden_layer\",\"10\",\"--n_neurons_per_layer\",\"560\",\"--num_batches_per_epoch\",\"100\",\"--prediction_length\",\"5\"]\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_CHANNEL_DATASET=/opt/ml/input/data/dataset\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_EPOCHS=100\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_BATCH_SIZE=256\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_CONTEXT_LENGTH=5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_PREDICTION_LENGTH=5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_LEARNING_RATE=0.001\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_N_HIDDEN_LAYER=10\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_N_NEURONS_PER_LAYER=560\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_DISTR_OUTPUT=StudentTOutput\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m SM_HP_NUM_BATCHES_PER_EPOCH=100\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Invoking script with the following command:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m /usr/bin/python3 sff.py --batch_size 256 --context_length 5 --distr_output StudentTOutput --epochs 100 --learning_rate 0.001 --n_hidden_layer 10 --n_neurons_per_layer 560 --num_batches_per_epoch 100 --prediction_length 5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m \r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Extension horovod.torch has not been built: /usr/local/lib/python3.8/dist-packages/horovod/torch/mpi_lib_v2.cpython-38-x86_64-linux-gnu.so not found\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Warning! MPI libs are missing, but python applications are still available.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m /usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m /usr/local/lib/python3.8/dist-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   warnings.warn(\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Traceback (most recent call last):\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m   File \"sff.py\", line 22, in <module>\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m     from gluonts.model.deep_factor import DeepFactorEstimator\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m ModuleNotFoundError: No module named 'gluonts.model.deep_factor'\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:31,433 sagemaker-training-toolkit ERROR    Reporting training FAILURE\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:31,433 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m ExitCode 1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m ErrorMessage \"\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m Command \"/usr/bin/python3 sff.py --batch_size 256 --context_length 5 --distr_output StudentTOutput --epochs 100 --learning_rate 0.001 --n_hidden_layer 10 --n_neurons_per_layer 560 --num_batches_per_epoch 100 --prediction_length 5\"\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p |\u001B[0m 2023-02-09 01:46:31,433 sagemaker-training-toolkit ERROR    Encountered exit_code 1\r\n",
      "\u001B[36mljdtjtdlf1-algo-1-xjt6p exited with code 1\n",
      "\u001B[0m1\n",
      "Aborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/Users/jbeckman/projects/capia/giia/out/giia-1.0.3/models/tmpmjr92391/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/local/image.py:248\u001B[0m, in \u001B[0;36m_SageMakerContainer.train\u001B[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 248\u001B[0m     \u001B[43m_stream_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;66;03m# _stream_output() doesn't have the command line. We will handle the exception\u001B[39;00m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;66;03m# which contains the exit code and append the command line to it.\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/local/image.py:916\u001B[0m, in \u001B[0;36m_stream_output\u001B[0;34m(process)\u001B[0m\n\u001B[1;32m    915\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m exit_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 916\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcess exited with code: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m exit_code)\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m exit_code\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 22\u001B[0m\n\u001B[1;32m     12\u001B[0m     train_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;66;03m# 'checkpoint_s3_uri': model_output_dir_uri,\u001B[39;00m\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_path\u001B[39m\u001B[38;5;124m'\u001B[39m: model_output_dir_uri,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_run\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m18\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m, \u001B[38;5;66;03m# 18 hours\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     }\n\u001B[1;32m     21\u001B[0m estimator \u001B[38;5;241m=\u001B[39m TRAIN\u001B[38;5;241m.\u001B[39mcreate_model(config\u001B[38;5;241m.\u001B[39mSM_ROLE, INSTANCE_TYPE, sagemaker_session, train_kwargs)\n\u001B[0;32m---> 22\u001B[0m \u001B[43mTRAIN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_dir_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/capia/giia/src/ml/train_sff.py:43\u001B[0m, in \u001B[0;36mTrain.fit_model\u001B[0;34m(self, estimator, dataset_dir_uri)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_model\u001B[39m(\u001B[38;5;28mself\u001B[39m, estimator: EstimatorBase, dataset_dir_uri: \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m---> 43\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset_dir_uri\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining job name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m estimator\u001B[38;5;241m.\u001B[39mlatest_training_job\u001B[38;5;241m.\u001B[39mjob_name)\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_data_path \u001B[38;5;241m=\u001B[39m Path(unquote(urlparse(estimator\u001B[38;5;241m.\u001B[39mmodel_data)\u001B[38;5;241m.\u001B[39mpath))\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py:248\u001B[0m, in \u001B[0;36mrunnable_by_pipeline.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    245\u001B[0m     run_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m self_instance\u001B[38;5;241m.\u001B[39msagemaker_session\u001B[38;5;241m.\u001B[39mcontext\n\u001B[0;32m--> 248\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/estimator.py:1102\u001B[0m, in \u001B[0;36mEstimatorBase.fit\u001B[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001B[0m\n\u001B[1;32m   1044\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Train a model using the input training dataset.\u001B[39;00m\n\u001B[1;32m   1045\u001B[0m \n\u001B[1;32m   1046\u001B[0m \u001B[38;5;124;03mThe API calls the Amazon SageMaker CreateTrainingJob API to start\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;124;03m    :class:`~sagemaker.workflow.pipeline_context.PipelineSession`\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_for_training(job_name\u001B[38;5;241m=\u001B[39mjob_name)\n\u001B[0;32m-> 1102\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlatest_training_job \u001B[38;5;241m=\u001B[39m \u001B[43m_TrainingJob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_new\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlatest_training_job)\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wait:\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/estimator.py:2004\u001B[0m, in \u001B[0;36m_TrainingJob.start_new\u001B[0;34m(cls, estimator, inputs, experiment_config)\u001B[0m\n\u001B[1;32m   1980\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Create a new Amazon SageMaker training job from the estimator.\u001B[39;00m\n\u001B[1;32m   1981\u001B[0m \n\u001B[1;32m   1982\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2000\u001B[0m \u001B[38;5;124;03m    all information about the started training job.\u001B[39;00m\n\u001B[1;32m   2001\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m train_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_train_args(estimator, inputs, experiment_config)\n\u001B[0;32m-> 2004\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msagemaker_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrain_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2006\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(estimator\u001B[38;5;241m.\u001B[39msagemaker_session, estimator\u001B[38;5;241m.\u001B[39m_current_job_name)\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/session.py:613\u001B[0m, in \u001B[0;36mSession.train\u001B[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001B[0m\n\u001B[1;32m    610\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m.\u001B[39mdumps(request, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m    611\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msagemaker_client\u001B[38;5;241m.\u001B[39mcreate_training_job(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrequest)\n\u001B[0;32m--> 613\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_intercept_create_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_request\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/session.py:4317\u001B[0m, in \u001B[0;36mSession._intercept_create_request\u001B[0;34m(self, request, create, func_name)\u001B[0m\n\u001B[1;32m   4304\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_intercept_create_request\u001B[39m(\n\u001B[1;32m   4305\u001B[0m     \u001B[38;5;28mself\u001B[39m, request: typing\u001B[38;5;241m.\u001B[39mDict, create, func_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=unused-argument\u001B[39;00m\n\u001B[1;32m   4306\u001B[0m ):\n\u001B[1;32m   4307\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This function intercepts the create job request.\u001B[39;00m\n\u001B[1;32m   4308\u001B[0m \n\u001B[1;32m   4309\u001B[0m \u001B[38;5;124;03m    PipelineSession inherits this Session class and will override\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4315\u001B[0m \u001B[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001B[39;00m\n\u001B[1;32m   4316\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4317\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/session.py:611\u001B[0m, in \u001B[0;36mSession.train.<locals>.submit\u001B[0;34m(request)\u001B[0m\n\u001B[1;32m    609\u001B[0m LOGGER\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating training-job with name: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, job_name)\n\u001B[1;32m    610\u001B[0m LOGGER\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, json\u001B[38;5;241m.\u001B[39mdumps(request, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m))\n\u001B[0;32m--> 611\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msagemaker_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_training_job\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/local/local_session.py:194\u001B[0m, in \u001B[0;36mLocalSagemakerClient.create_training_job\u001B[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001B[0m\n\u001B[1;32m    192\u001B[0m hyperparameters \u001B[38;5;241m=\u001B[39m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHyperParameters\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHyperParameters\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m    193\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting training job\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 194\u001B[0m \u001B[43mtraining_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mInputDataConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mOutputDataConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEnvironment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTrainingJobName\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    198\u001B[0m LocalSagemakerClient\u001B[38;5;241m.\u001B[39m_training_jobs[TrainingJobName] \u001B[38;5;241m=\u001B[39m training_job\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/local/entities.py:243\u001B[0m, in \u001B[0;36m_LocalTrainingJob.start\u001B[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_TRAINING\n\u001B[1;32m    241\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menvironment \u001B[38;5;241m=\u001B[39m environment\n\u001B[0;32m--> 243\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_artifacts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_data_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_data_config\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_name\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mend_time \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_COMPLETED\n",
      "File \u001B[0;32m~/projects/capia/giia/venv/lib/python3.8/site-packages/sagemaker/local/image.py:253\u001B[0m, in \u001B[0;36m_SageMakerContainer.train\u001B[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;66;03m# _stream_output() doesn't have the command line. We will handle the exception\u001B[39;00m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;66;03m# which contains the exit code and append the command line to it.\u001B[39;00m\n\u001B[1;32m    252\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to run: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (compose_command, \u001B[38;5;28mstr\u001B[39m(e))\n\u001B[0;32m--> 253\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    255\u001B[0m     artifacts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretrieve_artifacts(compose_data, output_data_config, job_name)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Failed to run: ['docker-compose', '-f', '/Users/jbeckman/projects/capia/giia/out/giia-1.0.3/models/tmpmjr92391/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Configure sagemaker and estimator\n",
    "#\n",
    "\n",
    "from ml.train_sff import Train\n",
    "\n",
    "TRAIN = Train(LOGGER)\n",
    "\n",
    "if IS_LOCAL:\n",
    "    train_kwargs = {}\n",
    "else:\n",
    "    train_kwargs = {\n",
    "        # 'checkpoint_s3_uri': model_output_dir_uri,\n",
    "        'output_path': model_output_dir_uri,\n",
    "        'code_location': model_output_dir_uri,\n",
    "        'use_spot_instances': True,\n",
    "        'max_wait': 18 * 60 * 60, # 18 hours\n",
    "        'max_run': 18 * 60 * 60, # 18 hours\n",
    "    }\n",
    "\n",
    "estimator = TRAIN.create_model(config.SM_ROLE, INSTANCE_TYPE, sagemaker_session, train_kwargs)\n",
    "TRAIN.fit_model(estimator, dataset_dir_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load model\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from gluonts.model.predictor import Predictor\n",
    "\n",
    "# Uncomment if you want to quickly compare AWS model with local model\n",
    "# IS_LOCAL = False\n",
    "\n",
    "if IS_LOCAL:\n",
    "    # model_output_dir_path is basically the same path as it was before, though sagemaker appends a random temp\n",
    "    # directory to the path. The path from TRAIN includes that random temp directory\n",
    "    # model_dir_path = TRAIN.model_data_path.parent.parent / \"model\"\n",
    "    model_dir_path = local_artifact_dir / \"local_cli\" / \"model\"\n",
    "else:\n",
    "    model_dir_path = AWS_HANDLER.download_model_from_s3(str(TRAIN.model_data_path), local_artifact_dir)\n",
    "\n",
    "LOGGER.log(f\"Model dir is [{model_dir_path}]\")\n",
    "predictor = Predictor.deserialize(model_dir_path)\n",
    "LOGGER.log(f\"Predictor metadata [{predictor.__dict__}]\")\n",
    "\n",
    "def plot_prob_forecasts(ts_list, forecast_list, plot_length=100):\n",
    "    for target, forecast in islice(zip(ts_list, forecast_list), len(forecast_list)):\n",
    "        prediction_intervals = (50.0, 90.0)\n",
    "        legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "        ax = target[-plot_length:].plot(figsize=(10, 7), linewidth=2)\n",
    "        forecast.plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        plt.grid(which=\"both\")\n",
    "        plt.legend(legend, loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_prob_forecasts_multi(ts_list, forecast_list, close_index, plot_length=60):\n",
    "    for target, forecast in islice(zip(ts_list, forecast_list), len(forecast_list)):\n",
    "        prediction_intervals = (50.0, 90.0)\n",
    "        legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "        target[close_index][-plot_length:].plot(ax=ax)  # plot the time series\n",
    "        forecast.copy_dim(close_index).plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        plt.grid(which=\"both\")\n",
    "        plt.legend(legend, loc=\"upper left\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define test data and make a prediction\n",
    "#\n",
    "\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.dataset.common import load_datasets\n",
    "from gluonts.dataset.stat import calculate_dataset_statistics\n",
    "from utils.splitter import DateSplitter\n",
    "\n",
    "import data_processing.gluonts_helper as gh\n",
    "\n",
    "test_dates = [\"2021-05-27 12:50:00\", \"2021-05-27 15:55:00\", \"2021-05-28 16:00:00\", \"2021-05-28 17:00:00\"]\n",
    "# test_dates = [\"2021-05-22 17:00:00\"]\n",
    "test_datasets = []\n",
    "feature_columns = []\n",
    "\n",
    "if FILEDATASET_BASED:\n",
    "    datasets = load_datasets(\n",
    "        metadata=(dataset_dir_path / config.METADATA_DATASET_FILENAME).parent,\n",
    "        train=(dataset_dir_path / config.TRAIN_DATASET_FILENAME).parent,\n",
    "        test=(dataset_dir_path / config.TEST_DATASET_FILENAME).parent,\n",
    "        one_dim_target=ONE_DIM_TARGET,\n",
    "        cache=True\n",
    "    )\n",
    "\n",
    "    feature_columns_map = {}\n",
    "    for feat in datasets.metadata.feat_static_cat:\n",
    "        if feat.name.startswith(\"feature_column_\"):\n",
    "            feature_index = int(feat.name.split(\"_\")[2])\n",
    "            feature_columns_map[feature_index] = feat.cardinality\n",
    "    feature_columns = [feature_columns_map.get(ele, 0) for ele in range(len(feature_columns_map))]\n",
    "\n",
    "    for idx, date in enumerate(test_dates):\n",
    "        # 1) Get splice of dataset for different dates with ample history\\n\",\n",
    "        splitter = DateSplitter(\n",
    "            prediction_length=-config.HYPER_PARAMETERS[\"prediction_length\"],\n",
    "            split_date=date,\n",
    "            max_history=config.FREQTRADE_MAX_CONTEXT,\n",
    "            # max_history=config.HYPER_PARAMETERS[\"context_length\"] + config.HYPER_PARAMETERS[\"prediction_length\"],\n",
    "        )\n",
    "        (_, train_dataset), (_, test_dataset) = splitter.split(datasets.test)\n",
    "\n",
    "        LOGGER.log(f\"Test dataset [{idx}] stats: {calculate_dataset_statistics(test_dataset)}\")\n",
    "        test_datasets.append(test_dataset)\n",
    "else:\n",
    "    test_dataset_filename = dataset_dir_path / config.TEST_CSV_FILENAME\n",
    "    test_df = pd.read_csv(filepath_or_buffer=test_dataset_filename, header=0, index_col=0)\n",
    "\n",
    "    feature_columns = gh.get_feature_columns(test_df, exclude_close=False)\n",
    "\n",
    "    for idx, date in enumerate(test_dates):\n",
    "        split_df = test_df[:date].tail(config.FREQTRADE_MAX_CONTEXT)\n",
    "        test_dataset = gh.df_to_multivariate_target_dataset(split_df, feature_columns)\n",
    "\n",
    "        LOGGER.log(f\"Test dataset [{idx}] stats: {calculate_dataset_statistics(test_dataset)}\")\n",
    "        test_datasets.append(test_dataset)\n",
    "\n",
    "print(f\"feature_columns are [{feature_columns}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluate and visualize the prediction\n",
    "#\n",
    "import json\n",
    "\n",
    "from gluonts.evaluation import Evaluator, MultivariateEvaluator\n",
    "\n",
    "for test_dataset in test_datasets:\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=test_dataset,  # test dataset\n",
    "        predictor=predictor,  # predictor\n",
    "        num_samples=100,  # number of sample paths we want for evaluation\n",
    "    )\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    forecast_entry = forecasts[0]\n",
    "    tss = list(ts_it)\n",
    "\n",
    "    # LOGGER.log(f\"Number of sample paths: {forecast_entry.num_samples}\")\n",
    "    # LOGGER.log(f\"Dimension of samples: {forecast_entry.samples.shape}\")\n",
    "    # LOGGER.log(f\"Start date of the forecast window: {forecast_entry.start_date}\")\n",
    "    # LOGGER.log(f\"Frequency of the time series: {forecast_entry.freq}\")\n",
    "\n",
    "    if ONE_DIM_TARGET:\n",
    "        evaluator = Evaluator(quantiles=[0.1])\n",
    "    else:\n",
    "        evaluator = MultivariateEvaluator(quantiles=[0.1])\n",
    "\n",
    "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_dataset))\n",
    "\n",
    "    for key in list(agg_metrics.keys()):\n",
    "        if key[0].isdigit():\n",
    "            del agg_metrics[key]\n",
    "    LOGGER.log(\"Aggregated performance\")\n",
    "    LOGGER.log(json.dumps(agg_metrics, indent=4))\n",
    "\n",
    "    if ONE_DIM_TARGET:\n",
    "        plot_prob_forecasts(tss, forecasts)\n",
    "    else:\n",
    "        close_index = feature_columns.index(\"close\")\n",
    "        # close_index = feature_columns.index(\"log_return_close\")\n",
    "        LOGGER.log(\"'close' performance\")\n",
    "        LOGGER.log(item_metrics.iloc[close_index])\n",
    "\n",
    "        plot_prob_forecasts_multi(tss, forecasts, close_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "\n",
    "def count_model_params(net: nn.HybridBlock) -> int:\n",
    "    params = net.collect_params()\n",
    "    num_params = 0\n",
    "    for p in params:\n",
    "        v = params[p]\n",
    "        num_params += np.prod(v.shape)\n",
    "    return num_params\n",
    "\n",
    "net_name = type(predictor.prediction_net).__name__\n",
    "num_model_param = count_model_params(predictor.prediction_net)\n",
    "print(f\"Number of parameters in {net_name}: {num_model_param}\")\n",
    "\n",
    "def plot_prob_forecasts_multi2(ts_list, forecast_list, close_index, plot_length=60):\n",
    "    for target, forecast in islice(zip(ts_list, forecast_list), len(forecast_list)):\n",
    "        print(forecast)\n",
    "        prediction_intervals = (50.0, 90.0)\n",
    "        legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "        target[close_index][-plot_length:].plot(ax=ax)  # plot the time series\n",
    "        forecast.copy_dim(close_index).plot(prediction_intervals=prediction_intervals, color='g')\n",
    "        plt.grid(which=\"both\")\n",
    "        plt.legend(legend, loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "# close_index = feature_columns.index(\"close\")\n",
    "# LOGGER.log(\"'close' performance\")\n",
    "# LOGGER.log(item_metrics.iloc[close_index])\n",
    "#\n",
    "# plot_prob_forecasts_multi2(tss, forecasts, close_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: FURTHER CELLS ARE COMPATIBLE WITH AWS SAGEMAKER ONLY, LOCAL MODE WILL NOT WORK\n",
    "# Hyperparameter tune the model\n",
    "#\n",
    "\n",
    "from ml.tune import Tune\n",
    "\n",
    "TUNE = Tune(UTILS, LOGGER)\n",
    "\n",
    "train_dataset_uri = f\"{dataset_dir_uri}/{config.TRAIN_DATASET_FILENAME}\"\n",
    "test_dataset_uri = f\"{dataset_dir_uri}/{config.TEST_DATASET_FILENAME}\"\n",
    "\n",
    "# Note: Feel free to tune the tuner, i.e. update max number of jobs and hyperparameters. Default is 10 jobs, but you\n",
    "# may want to change this as you refine the model. Additionally, if you find the best model has a parameter at the\n",
    "# end of the range you gave it, then you should look to move that range to determine if the model performs better\n",
    "# along that vector\n",
    "tuner = TUNE.create_tuner(estimator)\n",
    "TUNE.fit_tuner(tuner, dataset_dir_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get updates for Hyperparameter tune job. Ensure this is completed before going to the next cell\n",
    "#\n",
    "\n",
    "TUNE.get_tune_job_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluate the metrics of the tune job\n",
    "#\n",
    "\n",
    "TUNE.report_job_analytics()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giia (venv)",
   "language": "python",
   "name": "giia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
